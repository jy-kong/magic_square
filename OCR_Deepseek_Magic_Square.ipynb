{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries quietly (-q suppresses output)\n",
        "!pip install gradio pillow easyocr -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwWyUV8-Mxev",
        "outputId": "c8256382-9130-4090-a7f9-9d132df7a238"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.6/286.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os # Provides access to environment variables and file system operations\n",
        "import numpy as np  # NumPy for numerical operations and array manipulation\n",
        "from PIL import Image  # Image processing library\n",
        "import easyocr  # Optical Character Recognition (OCR) for text extraction from images\n",
        "import requests  # For making HTTP requests (e.g., fetching data from URLs)\n",
        "import json  # Handling JSON data\n",
        "import gradio as gr  # Building interactive web-based applications"
      ],
      "metadata": {
        "id": "bLwEtiRIO4d8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# DeepSeek API configuration\n",
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get('deepseek_api')  # Retrieves the secret from environment variables\n",
        "DEEPSEEK_API_URL = \"https://api.deepseek.com/v1/chat/completions\"\n",
        "\n",
        "def extract_numbers(image_path):\n",
        "    \"\"\"Extracts all characters from an image and arranges them into a 3x3 grid, replacing non-digits with '?'.\"\"\"\n",
        "    results = reader.readtext(image_path, detail=1)  # Get bounding boxes with text\n",
        "\n",
        "    detected_cells = []\n",
        "    for (bbox, text, prob) in results:\n",
        "        # Replace non-digit characters with '?'\n",
        "        detected_cells.append(text if text.isdigit() else '?')  # Collect all detected text, replace non-digits with '?'\n",
        "\n",
        "    if not detected_cells:\n",
        "        return [['?', '?', '?'], ['?', '?', '?'], ['?', '?', '?']]  # Return a grid with '?' if nothing is detected\n",
        "\n",
        "    # Step 1: Create a 3x3 grid and fill it with the detected characters row by row\n",
        "    grid = [['?', '?', '?'], ['?', '?', '?'], ['?', '?', '?']]  # Initialize with '?' as placeholders\n",
        "    i = 0  # Start filling from the first detected character\n",
        "\n",
        "    # Step 2: Place the detected characters in the grid\n",
        "    for row in range(3):\n",
        "        for col in range(3):\n",
        "            if i < len(detected_cells):\n",
        "                grid[row][col] = detected_cells[i]  # Place the detected character in the grid\n",
        "                i += 1\n",
        "\n",
        "    return grid\n",
        "\n",
        "def format_puzzle_for_deepseek(grid):\n",
        "    \"\"\"Formats the extracted puzzle with variable placeholders for missing values.\"\"\"\n",
        "    variables = {}\n",
        "    variable_index = 0\n",
        "    formatted_grid = []\n",
        "\n",
        "    for row in grid:\n",
        "        formatted_row = []\n",
        "        for cell in row:\n",
        "            if cell == \"?\":\n",
        "                variable_name = chr(65 + variable_index)  # Assign 'A', 'B', 'C'...\n",
        "                variables[variable_name] = \"?\"\n",
        "                formatted_row.append(variable_name)\n",
        "                variable_index += 1\n",
        "            else:\n",
        "                formatted_row.append(cell)\n",
        "        formatted_grid.append(formatted_row)\n",
        "\n",
        "    return formatted_grid, variables\n",
        "\n",
        "def solve_with_deepseek(formatted_grid, variables):\n",
        "    \"\"\"Sends the formatted puzzle to DeepSeek-Chat for step-by-step solving.\"\"\"\n",
        "    puzzle_text = \"\\n\".join([\"\\t\".join(row) for row in formatted_grid])\n",
        "    prompt = (\n",
        "        \"You are an AI specialized in solving magic square puzzles. Analyze the following grid, where missing values are already \"\n",
        "        \"assigned as variables (e.g., A, B, C, D, E). Provide the correct solution with step-by-step reasoning. Ensure the sum of \"\n",
        "        \"each row, column, and diagonal is the same. Duplicates are not allowed in any row, column, or diagonal.\\n\\n\"\n",
        "        f\"Given Question:\\n{puzzle_text}\\n\\n\"\n",
        "        \"The missing values are represented as variables (e.g., A, B, C, D, E). Provide a structured solution.\"\n",
        "        \"\\nFormat your response strictly as follows:\\n\"\n",
        "        \"1. **Given Question**:\\n   - (grid format with missing values as variables)\\n\"\n",
        "        \"2. **Step-by-step Reasoning**:\\n   - Identify the missing values logically\\n   - Explain the rules used\\n   - Calculate step-by-step\\n\"\n",
        "        \"3. **Final Answer**:\\n   - Completed grid\\n\"\n",
        "        \"4. **Validation**:\\n   - Verify all row/column sums\\n\"\n",
        "    )\n",
        "\n",
        "    data = {\n",
        "        \"model\": \"deepseek-chat\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0,\n",
        "        \"max_tokens\": 2000\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=data, timeout=300)\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "        return result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"Error: No response content.\")\n",
        "    except requests.exceptions.Timeout:\n",
        "        return \"Error: DeepSeek API request timed out. Please try again.\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error: DeepSeek API failed: {str(e)}\"\n",
        "\n",
        "\n",
        "def solve_magic_square(image):\n",
        "    \"\"\"Main function to extract, format, solve, and validate a magic square puzzle.\"\"\"\n",
        "    image_path = \"uploaded_magic_square.png\"\n",
        "    image.save(image_path)\n",
        "    extracted_grid = extract_numbers(image_path)\n",
        "    formatted_grid, variables = format_puzzle_for_deepseek(extracted_grid)\n",
        "    solution = solve_with_deepseek(formatted_grid, variables)\n",
        "    return solution"
      ],
      "metadata": {
        "id": "ECKmQYlFO6Ei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39507d5-8561-41eb-cbbc-7f76afa9158f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=solve_magic_square,  # Function to call for OCR and solving\n",
        "    inputs=gr.Image(type=\"pil\"),  # Input type: PIL image\n",
        "    outputs=gr.Textbox(),  # Output type: Textbox to display extracted and solved result\n",
        "    title=\"Magic Square Puzzle Solver\",  # Title of the interface\n",
        "    description=(\n",
        "        \"Upload an image of a 3x3 Magic Square puzzle. \\n\\n\"\n",
        "        \"- A Magic Square is a 3x3 grid where the sum of each row, column, and diagonal is the same. \\n\"\n",
        "        \"- The puzzle involves solving for missing values represented by variables (e.g., A, B, C, D, E). \\n\"\n",
        "        \"- Please note that this tool only works with 3x3 puzzles. Duplicates are not allowed in any row, column, or diagonal.\\n\"\n",
        "    ),  # Detailed description of the game rules\n",
        "    allow_flagging=\"never\"  # Disables the flagging feature for now\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "a9TPyN0fMxhl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "0760158e-b320-4e99-8330-f86e33740d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://16d4506540d0cfd9a0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://16d4506540d0cfd9a0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}